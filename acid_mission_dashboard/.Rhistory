setkey(df_all, user_id, time)
View(session_sql)
df_all[type == "LOGIN", token := 1]
View(session_sql)
View(df_all)
df_all[, token := 0]
df_all[type == "LOGIN", token := 1]
View(df_all)
df_all[, token := cumsum(token), by = "user_id"]
View(df_all)
df_all[, longtoken := paste0(user_id, "_", token)]
View(df_all)
View(df_all)
token_filter <- df_all[, list(len = length(time)), by = c("longtoken", "token")]
View(token_filter)
length(fs_all$time)
length(df_all$time)
rm(list = ls()); gc(); gc()
options(java.parameters = "-Xmx4096m")
options(java.parameters = "-XX:-UseConcMarkSweepGC")
options(java.parameters = "-XX:-UseGCOverheadLimit")
options(bitmapType='cairo')
options(scipen = 999)
require(RODBC)
# require(XML)
require(data.table)
# require(plyr)
# require(dplyr)
require(reshape2)
require(zoo)
# require(compiler)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(rJava)
require(xlsx)
require(ggplot2)
# require(Cairo)
# require(grid)
# require(scales)
# require(RColorBrewer)
# Define your workspace: "X:/xxx/"
workspace <- "M:/Documents/gitlab/mmho/playtime_test"
# Connecting to the database
server <- "MMHO_DE"
range <- c(20140629, gsub("-", "", Sys.Date()-1))
# range <- c(gsub("-", "", Sys.Date()-30), gsub("-", "", Sys.Date()-1))
myconn <- odbcConnect(server, uid="", pwd="")
session_sql <- sqlQuery(myconn,
paste0("SELECT user_id, ",
"extractvalue(data, '//sessionId') as session_id, ",
"extractvalue(data, '//disconnectedByTimeOut') as timeout, ",
"extractvalue(data, '//errorCode') as error, ",
"type, scope, idleTime, ",
"dateDim, cast(time as character) as time ",
"FROM fct_sessions ",
"WHERE scope = 'In-Game' AND dateDim >= ", range[1],
" AND dateDim <= ", range[2])
, stringsAsFactors=FALSE)
View(session_sql)
df_all <- data.table(session_sql)
df_all[, time := as.POSIXct(strptime(time, "%Y-%m-%d %H:%M:%S"))]
setkey(df_all, user_id, session_id, time)
View(df_all)
df_all[, len_logs := length(time), keyby = c("user_id", "session_id")]
View(df_all)
df_all[, len_login := length(time[type == "LOGIN"]), keyby = c("user_id", "session_id")]
View(df_all)
df_bad <- subset(df_all, len_login * 2 != len_logs)
?distinct
?distinct()
?unique
length(unique(df_bad$user_id))
length(unique(df_all$user_id))
length(unique(df_all$session_id))
length(unique(df_bad$session_id))
length(unique(df_bad$session_id))/length(unique(df_all$session_id))
length(unique(df_bad$session_id))/length(unique(df_all$session_id))
df_all <- subset(df_all, len_login * 2 == len_logs)
# flag and keep good users: LOGOUT follows LOGIN
df_all[, good := ifelse(type == rep(c("LOGIN", "LOGOUT"), times = unique(len_login)), 1, 0)
, keyby = c("user_id", "session_id")]
df_all <- subset(df_all, good == 1)
View(df_all)
df_all <- data.table(session_sql)
df_all[, time := as.POSIXct(strptime(time, "%Y-%m-%d %H:%M:%S"))]
setkey(df_all, user_id, session_id, time)
# length(time) gives the count of rows (could be length(anything))
# get number of logins+logouts by user_id and session_id
df_all[, len_logs := length(time), keyby = c("user_id", "session_id")]
# get only number of logins
df_all[, len_login := length(time[type == "LOGIN"]), keyby = c("user_id", "session_id")]
# a <- subset(df_all, len_logs == 2 & len_login == 2)
# get "obviously bad" users
df_bad <- subset(df_all, len_login * 2 != len_logs)
# 0.05 bad sessions_ids
total_sessions <- length(unique(df_all$session_id))
length(unique(df_bad$session_id))/total_sessions
length(unique(df_all$session_id))/total_sessions
df_all <- subset(df_all, len_login * 2 == len_logs)
# flag and keep good users: LOGOUT follows LOGIN
df_all[, good := ifelse(type == rep(c("LOGIN", "LOGOUT"), times = unique(len_login)), 1, 0)
, keyby = c("user_id", "session_id")]
df_all <- subset(df_all, good == 1)
length(unique(df_all$session_id))/total_sessions
View(df_all)
View(df_all)
df_data <- subset(df_all, select = c("user_id", "session_id", "type", "dateDim", "time"))
setkey(df_data, user_id, time)
df_data[, secs := c(NA, as.integer(difftime(time[-1], time[-length(time)], units = "secs"))), keyby = "user_id"]
View(df_data)
View(df_data)
df_data[, token := ifelse(is.na(secs) | (type == "LOGIN" & secs > 300), 1, 0)]
View(df_data)
df_data[, playsession := cumsum(token)]
# if == LOGOUT, then secs, 0 if else
df_data[, lenSecs := as.integer(type == "LOGOUT") * secs]
View(df_data)
df_data[, lenSecs := sum(lenSecs, na.rm = TRUE), by = c("user_id", "playsession")]
View(df_data)
rm(list=ls())
gc();gc()
####Query
#install.packages("RODBC")
library(RODBC)
library(reshape2)
library(ggplot2)
library(data.table)
#library(lubridate)
library(bbbi)
workspace <- "C:/Users/christoph.safferling/Desktop/temp/R"
setwd(workspace)
conn <-odbcConnect(dsn="MMHO_DE")
query <- "
select t1.user_id, t2.user_id, reg_date, year(reg_date) as reg_year, month(reg_date) as reg_month,
concat(year(reg_date), '_', month(reg_date)) as cohort, campaignkey,
provider, realcurrencyamount, date(datedim) as purchase_date, time as purchase_time,
datediff(date(datedim), reg_date) as user_age_at_purchase
from fct_payments as t1
join(
SELECT user_id, campaignkey, date(datedim) as reg_date
FROM fct_campaign_click
where step = 'REGISTERED'
group by user_id
) as t2 on t1.user_id = t2.user_id
"
#query <- gsub("\n"," ", query)
sqldata <- sqlQuery(conn, query, stringsAsFactors=FALSE)
sqldata$cohort <- as.factor(data$cohort)
close(conn)
plot(density(x=sqldata$user_age_at_purchase))
data <- as.data.table(sqldata)
setkey(data, cohort, user_age_at_purchase)
View(data)
setkey(data, cohort, user_age_at_purchase)
data <- data[, rev:=sum(realcurrencyamount), by = list(cohort, user_age_at_purchase)]
View(data)
ts <- summaryBy(rev ~ cohort+user_age_at_purchase, data=data)
library(RODBC)
library(reshape2)
library(ggplot2)
library(data.table)
#library(lubridate)
library(bbbi)
library(doBy)
ts <- summaryBy(rev ~ cohort+user_age_at_purchase, data=data)
ts <- ts[, cumrev:=cumsum(rev), by = list(cohort)]
ts <- as.data.table(ts)
setkey(ts, user_age_at_purchase)
ts <- ts[, cumrev:=cumsum(rev), by = list(cohort)]
setkey(ts, cohort, user_age_at_purchase)
View(ts)
ts <- ts[, cumrev:=cumsum(rev), by(cohort)]
View(ts)
?data.table()
ts <- ts[, cumrev:=cumsum(rev), by list("cohort", "user_age_at_purchase")]
ts <- ts[, cumrev:=cumsum(rev), by = list("cohort", "user_age_at_purchase")]
ts <- ts[, cumrev:=cumsum(rev), by = list("cohort")]
ts <- ts[, cumrev:=cumsum(rev), by = list("cohort", user_age_at_purchase), roll=TRUE
]
ts <- ts[, cumrev:=cumsum(rev), by = list("cohort", "user_age_at_purchase"), roll=TRUE]
Tables()
tables()
X = data.table(c("b","c"),foo=c(4,2))
X
DT[X]
DT = data.table(x=rep(c("a","b","c"),each=3), y=c(1,3,6), v=1:9)
tables
tables()
setkey(DT,x)
tables()
DT
x
X
DT[,2]
DT[,2,with=FALSE]
DT[2:3,sum(v)]
DT
DT["a"]
DT[,sum(v),by=x]
DT[X]
DT
X
DT[X]
DT["a"]
DT[J("a",3)]
DT[J("a",3:6)]
DT[J("a",3:6),nomatch=0]
DT[X]
DT[X,sum(v)]
ts
ts <- ts[, cumrev:=cumsum(rev), by = list("cohort", "user_age_at_purchase"), roll=TRUE]
ts[, sum(rev)]
ts[, sum(rev), by=cohort]
ts[, sum(rev), by="cohort"]
ts[, sum(rev), by=list("cohort")]
ts
tables()
names(ts)
ts[, cumrev:=cumsum(rev.mean), by = list("cohort", "user_age_at_purchase"), roll=TRUE]
ts[, cumrev:=cumsum(rev.mean)]
ts[, cumsum(rev.mean)]
ts[, cumsum(rev.mean), by=list("cohort")]
ts[, cumsum(rev.mean), by=list(cohort)]
ts[, select=c("cohort","user_age_at_purchase",cumsum(rev.mean)), by=list(cohort)]
ts[, cumsum(rev.mean), by=list(cohort)]
test <- ts[, cumsum(rev.mean), by=list(cohort)]
View(test)
test <- ts[, cumsum:=cumsum(rev.mean), by=list(cohort)]
View(test)
test <- ts[, cumsum2:=cumsum(rev.mean), by=list(cohort), roll=TRUE]
View(test)
max(ts$user_age_at_purchase)
user_age <- seq(1:max(ts$user_age_at_purchase))
user_age
ts[user_age]
ts[user_age, roll=TRUE]
user_age
expand.grid(x = 1:10, y = 11:20)
a <- data.table(expand.grid(x = 1:10, y = 11:20))
seetkey(a, x, y)
setkey(a, x, y)
View(a)
a <- data.table(expand.grid(cohort = unique(ts$cohort), y = unique(ts$user_age_at_purchase)))
a <- data.table(expand.grid(cohort = unique(ts$cohort), user_age_at_purchase = unique(ts$user_age_at_purchase)))
head(a)
a <- data.table(expand.grid(cohort = unique(ts$cohort), user_age_at_purchase = unique(ts$user_age_at_purchase)))
setkey(a, cohort, user_age_at_purchase)
a
View(a)
a <- merge(a, ts, by = intersect(names(a), names(ts)), all.x = TRUE)
View(a)
a[is.na(rev.mean), rev.mean := 0]
View(a)
?expand.grid()
View(DT)
View(ts)
a <- data.table(expand.grid(cohort = unique(ts$cohort), user_age_at_purchase = unique(ts$user_age_at_purchase)))
a <- merge(a, ts, by = intersect(names(a), names(ts)), all.x = TRUE)
a[is.na(rev.mean), rev.mean := 0]
View(a)
ts <- merge(a, ts, by = intersect(names(a), names(ts)), all.x = TRUE)
ts[is.na(rev.mean), rev.mean := 0]
View(ts)
ts[, 1:3, with=FALSE]
ts[, cumsum(rev.mean), by=cohort]
ts[, cumsum:=cumsum(rev.mean), by=cohort]
ts <- ts[, cumsum:=cumsum(rev.mean), by=cohort]
View(ts)
ts[, !c("cumrev","cumsum2")]
ts[, !list(cumrev,cumsum2)]
ts[, cumrev=NULL]
colNum =2
ts[, select=list(cohort, user_age_at_purchase,rev.mean,cumsum)]
ts[, list(cohort, user_age_at_purchase,rev.mean,cumsum)]
ts <- ts[, list(cohort, user_age_at_purchase,rev.mean,cumsum)]
data <- as.data.table(sqldata)
setkey(data, cohort, user_age_at_purchase)
data <- data[, rev:=sum(realcurrencyamount), by = list(cohort, user_age_at_purchase)]
ts <- summaryBy(rev ~ cohort+user_age_at_purchase, data=data)
ts <- as.data.table(ts)
setkey(ts, cohort, user_age_at_purchase)
# get all possible combinations and expand.grid on them
a <- data.table(expand.grid(cohort = unique(ts$cohort), user_age_at_purchase = unique(ts$user_age_at_purchase)))
# merge back into ts,
ts <- merge(a, ts, by = intersect(names(a), names(ts)), all.x = TRUE)
# update NAs with 0
ts[is.na(rev.mean), rev.mean := 0]
# keep rows 1-3
ts[, 1:3, with=FALSE]
ts <- ts[, cumsum:=cumsum(rev.mean), by=cohort]
ts <- ts[, 1:3, with=FALSE]
ts <- ts[, cumsum:=cumsum(rev.mean), by=cohort]
View(ts)
ggplot(data=ts, aes(x=user_age_at_purchase, y=cumsum, group=cohort, colour=cohort)) +
geom_line() +
geom_point(size=4, shape=21, fill="white")
ggplot(data=ts, aes(x=user_age_at_purchase, y=cumsum, group=cohort, colour=cohort)) +
#    geom_point(size=4, shape=21, fill="white") +
geom_line()
View(ts)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv", method = "curl")
download.file(fileUrl, destfile = "gdp.csv")
gdp <- read.csv("./gdp.csv")
View(gdp)
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
# download from the URL
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
# download from the URL
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
combined[with(combined, order(-V2) )]
View(combined)
library(dplyr)
arrange(combined, desc(V1))
data <- arrange(combined, desc(V1))
data
View(data)
data <- arrange(combined, desc(V2))
View(data)
str(data)
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
library("rJava")
R.Version()
install.packages('rJava', repos='http://www.rforge.net/')
library(httr)
set_config(use_proxy(url="10.26.0.16", port=3128))
install.packages('rJava', .libPaths()[1], 'http://www.rforge.net/')
install.packages('rJava', .libPaths()[1], 'http://www.rforge.net/', type="source")
myData <- data.frame( x=1:10, y=sample(1:10), z=rnorm(10) )
myData
head(myData, -1)
tail(myData, -1)
?head()
source('~/games/gitlab/mmho/hero_count.R')
mysqlconn <-odbcConnect(dsn="MMHO_DE", uid="", pwd="")
heroes <- sqlQuery(mysqlconn,"
select gen.user_id, generated_heroes, deleted_heroes, generated_heroes - deleted_heroes heroes
from(
SELECT user_id, count(1) generated_heroes
FROM mmho_emea_de_gimpli_warehouse.fct_generate_hero
group by user_id
) as gen
left outer join(
SELECT user_id, count(1) deleted_heroes
FROM mmho_emea_de_gimpli_warehouse.fct_delete_hero
group by user_id
) as del on gen.user_id = del.user_id
", stringsAsFactors=FALSE)
View(heroes)
close(mysqlconn)
source('~/games/gitlab/mmho/hero_count.R')
View(heroes)
geom_histogram()
q <- ggplot(heroes, aes(x=heroes))+
geom_histogram()
library(ggplot2)
q <- ggplot(heroes, aes(x=heroes))+
geom_histogram()
q
table(heroes$heroes)
q <- ggplot(heroes, aes(x=heroes))+
geom_histogram(binwidth=1)
q
source('~/games/gitlab/mmho/hero_count.R')
View(heroes)
table(heroes$rating_for_week)
table(heroes$heroes)
q <- ggplot(heroes, aes(x=heroes, color=rating_for_week))+
geom_histogram(binwidth=1)
q
q <- ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_histogram(binwidth=1)
q
q <- ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_histogram(binwidth=1)+
geom_bar(position="dodge")
q
table(heroes$heroes, heroes$rating_for_week)
table(heroes$rating_for_week, heroes$heroes)
ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_histogram(binwidth=1)+
geom_bar(position="dodge")
ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_bar(position="dodge")+
geom_histogram(binwidth=1)
ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_bar(position="dodge", binwidth=1)
ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_freqpoly(binwidth=1000)
ggplot(heroes, aes(x=heroes, ..density.., fill=rating_for_week))+
geom_freqpoly(binwidth=1000)
ggplot(heroes, aes(x=heroes, fill=rating_for_week))+
geom_density()
ggplot(heroes, aes(x=heroes, color=rating_for_week))+
geom_density()
?read.csv
update.packages(checkBuilt=TRUE, ask=FALSE)
install.packages("dpylr")
install.packages("dplyr")
install.packages("dplyr", dependencies=TRUE)
rm(list = ls()); gc(); gc()
update.packages(checkBuilt=TRUE, ask=FALSE)
install.packages("ggplot2", dependencies=TRUE)
View(heroes)
View(heroes)
install.packages("httr")
rm(list = ls()); gc(); gc()
seq_along(5)
seq_along(1,5)
?seq_along
seq_len(5)
paste0("SELECT games_id, date_dim, sum(real_currency_eur) turnover, sum(net_net_eur) gimpli_net_eur, ",
"sum(coalesce(cast(substring_index(substring_index(`data`, '<turnover_minus_vat_minus_fees>', -1), '</turnover_minus_vat_minus_fees>', 1) as FLOAT),0)/exchange_rate) psm_net_eur ",
"from ao_emea_int_20.fct_payments_information ",
"WHERE date_dim between ", range[1], " and ", range[2], " ",
"and lower(status) = 'purchased' and games_id != 'AO ABE ALL' ",
"group by games_id, date_dim ",
"order by games_id, date_dim "
)
range <- c(20141101, 20150409)
range <- c(20141101, 20150415)
paste0("SELECT games_id, date_dim, sum(real_currency_eur) turnover, sum(net_net_eur) gimpli_net_eur, ",
"sum(coalesce(cast(substring_index(substring_index(`data`, '<turnover_minus_vat_minus_fees>', -1), '</turnover_minus_vat_minus_fees>', 1) as FLOAT),0)/exchange_rate) psm_net_eur ",
"from ao_emea_int_20.fct_payments_information ",
"WHERE date_dim between ", range[1], " and ", range[2], " ",
"and lower(status) = 'purchased' and games_id != 'AO ABE ALL' ",
"group by games_id, date_dim ",
"order by games_id, date_dim "
)
update.packages(checkBuilt = TRUE, ask = FALSE)
install.packages(c(knitr, yaml, htmltools, caTools, bitops, rmarkdown))
install.packages(c("knitr", "yaml", "htmltools", "caTools", "bitops", "rmarkdown"))
load("D:/gitlab/tso/biabb 2023 check TSO tracking.Rdata")
rm(heroes)
View(info)
View(add_remove)
info %>% filter(grepl('event', name, ignore.case=TRUE))
library(dplyr)
install.packages("dplyr")
info %>% filter(grepl('event', name, ignore.case=TRUE))
library(dplyr)
info %>% filter(grepl('event', name, ignore.case=TRUE))
?file.exists
?if
()
??if
??conditional
?load
?addDataFrame
update.packages(checkBuilt = TRUE, ask = FALSE)
library(slidify)
wd <- "D:/github/game_analytics"
setwd(wd)
author("game-analytics")
slidify("index.Rmd")
slidify("index.Rmd")
install.packages(c("shiny", "markdown", "rpivot"))
install.packages(c("shiny", "markdown", "rpivot"))
install.packages(c("shiny", "markdown", "rpivot"))
install.packages(c("shiny", "markdown", "rpivot"))
install.packages("shiny")
install.packages("rpivot")
install.packages("rpivotTable")
install.packages("grid")
devtools::install_github(c("ramnathv/htmlwidgets", "smartinsightsfromdata/rpivotTable"))
library(httr)
set_config(use_proxy(url="10.26.0.16", port=3128))
devtools::install_github(c("ramnathv/htmlwidgets", "smartinsightsfromdata/rpivotTable"))
install.packages("bit64")
setwd("D:/github/game_analytics/acid_mission_dashboard/")
load("acid_mission_dashboard.Rda")
runApp(launch.browser = TRUE)
suppressPackageStartupMessages(library(shiny))
runApp(launch.browser = TRUE)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
